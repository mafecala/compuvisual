# ğŸ•º Taller - Reconocimiento de Acciones Corporales con MediaPipe

## ğŸ“… Fecha

2025-06-20


##  ğŸŒ· Equipo de trabajo

  

**Mi grupo estÃ¡ conformado por:**

  

- JuliÃ¡n RamÃ­rez DÃ­az (julramirezdi@unal.edu.co)

- JuliÃ¡n David RincÃ³n Orjuela (jurinconor@unal.edu.co)

- MarÃ­a Fernanda Cala RodrÃ­guez (mcalar@unal.edu.co)

  

**Este taller fue realizado por:**

  

- MarÃ­a Fernanda Cala RodrÃ­guez (mcalar@unal.edu.co)
---

## ğŸ¯ Objetivo del Taller

Implementar el reconocimiento de acciones simples (como sentarse, levantar brazos o caminar frente a cÃ¡mara) usando MediaPipe Pose para detectar la postura corporal. El objetivo es utilizar puntos clave del cuerpo (landmarks) para interpretar la acciÃ³n y responder visualmente o con sonidos.

---

## ğŸ§  Conceptos Aprendidos

âœ… Captura de video en tiempo real con OpenCV  
âœ… DetecciÃ³n de postura corporal con MediaPipe Pose  
âœ… ExtracciÃ³n y anÃ¡lisis de landmarks corporales  
âœ… LÃ³gica para interpretaciÃ³n de acciones humanas  
âœ… VisualizaciÃ³n de acciones con overlays y texto  
âœ… DetecciÃ³n de caminata mediante movimiento alternado  
âœ… EvaluaciÃ³n de precisiÃ³n y errores en tiempo real

---

## ğŸ”§ Herramientas Utilizadas

- Python 3.x
- OpenCV (`opencv-python`)
- MediaPipe (`mediapipe`)
- NumPy
- (Opcional) Pygame para efectos sonoros
- (Opcional) Tkinter o GUI con `cv2.putText`

---

## ğŸ§ª Acciones Reconocidas

| AcciÃ³n              | Criterio lÃ³gico basado en landmarks             |
|---------------------|-------------------------------------------------|
| ğŸ™Œ Brazos levantados | Ambas muÃ±ecas por encima de la nariz           |
| ğŸª‘ Persona sentada   | Caderas por debajo de las rodillas             |
| ğŸš¶ Caminando         | Alternancia en la posiciÃ³n vertical de los pies|

---

## ğŸ“· Demo (GIF)

![demo](demo.gif)

---

## ğŸ“ Estructura del Proyecto

acciones_pose/
â”œâ”€â”€ taller37.py
â”œâ”€â”€ README.md

---


## ğŸ” Fragmento de cÃ³digo relevante

`if left_wrist_y < nose_y and right_wrist_y < nose_y:
    action = "ğŸ™Œ Brazos levantados"  elif left_hip_y > left_knee_y and right_hip_y > right_knee_y:
    action = "ğŸª‘ Persona sentada"  else: if  abs(left_foot_y - prev_left_foot_y) > 0.02  or  abs(right_foot_y - prev_right_foot_y) > 0.02:
        walking_counter += 1  if walking_counter > walk_threshold:
        action = "ğŸš¶ Caminando"`
        
## ğŸ¤– Prompt Usado
```
Crear un script de Python que use MediaPipe Pose para detectar acciones humanas bÃ¡sicas (sentado, brazos arriba, caminando). El script debe capturar video en tiempo real con OpenCV, procesar los landmarks del cuerpo y mostrar la acciÃ³n detectada en pantalla.
```

## ğŸ’¬ ReflexiÃ³n Final

Durante la implementaciÃ³n del reconocimiento de acciones, la acciÃ³n mÃ¡s sencilla de detectar fue "brazos arriba", ya que las muÃ±ecas tienen un movimiento muy notorio respecto a la cabeza.

En contraste, la detecciÃ³n de "caminata" fue mÃ¡s desafiante debido a su variabilidad: las posiciones de los pies cambian sutilmente y requieren umbrales bien ajustados para evitar falsos positivos.

TambiÃ©n se observÃ³ que la acciÃ³n de "sentarse" puede generar falsos positivos si el usuario se inclina o baja el torso sin flexionar completamente las piernas. Esto destaca la necesidad de afinar mÃ¡s los criterios lÃ³gicos y considerar mÃ¡s puntos del cuerpo (como los tobillos o el Ã¡ngulo de las piernas) para una clasificaciÃ³n robusta.

Este ejercicio me ayudÃ³ a comprender no solo el funcionamiento interno de MediaPipe, sino tambiÃ©n la complejidad de traducir posturas humanas a reglas lÃ³gicas interpretables por cÃ³digo.

