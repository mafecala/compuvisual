{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe1175ed-5d5e-46f0-954c-92f6a372348b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\usuario\\documents\\anaconda\\lib\\site-packages (4.11.0.86)\n",
      "Collecting mediapipe\n",
      "  Using cached mediapipe-0.10.21-cp312-cp312-win_amd64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\usuario\\documents\\anaconda\\lib\\site-packages (1.26.4)\n",
      "Collecting absl-py (from mediapipe)\n",
      "  Using cached absl_py-2.2.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\usuario\\documents\\anaconda\\lib\\site-packages (from mediapipe) (23.1.0)\n",
      "Collecting flatbuffers>=2.0 (from mediapipe)\n",
      "  Using cached flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting jax (from mediapipe)\n",
      "  Using cached jax-0.6.0-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting jaxlib (from mediapipe)\n",
      "  Using cached jaxlib-0.6.0-cp312-cp312-win_amd64.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\usuario\\documents\\anaconda\\lib\\site-packages (from mediapipe) (3.9.2)\n",
      "Collecting opencv-contrib-python (from mediapipe)\n",
      "  Using cached opencv_contrib_python-4.11.0.86-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: protobuf<5,>=4.25.3 in c:\\users\\usuario\\documents\\anaconda\\lib\\site-packages (from mediapipe) (4.25.3)\n",
      "Collecting sounddevice>=0.4.4 (from mediapipe)\n",
      "  Using cached sounddevice-0.5.2-py3-none-win_amd64.whl.metadata (1.6 kB)\n",
      "Collecting sentencepiece (from mediapipe)\n",
      "  Using cached sentencepiece-0.2.0-cp312-cp312-win_amd64.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: CFFI>=1.0 in c:\\users\\usuario\\documents\\anaconda\\lib\\site-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n",
      "Collecting ml_dtypes>=0.5.0 (from jax->mediapipe)\n",
      "  Using cached ml_dtypes-0.5.1-cp312-cp312-win_amd64.whl.metadata (22 kB)\n",
      "Collecting opt_einsum (from jax->mediapipe)\n",
      "  Using cached opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: scipy>=1.11.1 in c:\\users\\usuario\\documents\\anaconda\\lib\\site-packages (from jax->mediapipe) (1.13.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\usuario\\documents\\anaconda\\lib\\site-packages (from matplotlib->mediapipe) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\usuario\\documents\\anaconda\\lib\\site-packages (from matplotlib->mediapipe) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\usuario\\documents\\anaconda\\lib\\site-packages (from matplotlib->mediapipe) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\usuario\\documents\\anaconda\\lib\\site-packages (from matplotlib->mediapipe) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\usuario\\documents\\anaconda\\lib\\site-packages (from matplotlib->mediapipe) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\usuario\\documents\\anaconda\\lib\\site-packages (from matplotlib->mediapipe) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\usuario\\documents\\anaconda\\lib\\site-packages (from matplotlib->mediapipe) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\usuario\\documents\\anaconda\\lib\\site-packages (from matplotlib->mediapipe) (2.9.0.post0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\usuario\\documents\\anaconda\\lib\\site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.21)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\usuario\\documents\\anaconda\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n",
      "Using cached mediapipe-0.10.21-cp312-cp312-win_amd64.whl (51.0 MB)\n",
      "Using cached flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Using cached sounddevice-0.5.2-py3-none-win_amd64.whl (363 kB)\n",
      "Using cached absl_py-2.2.2-py3-none-any.whl (135 kB)\n",
      "Using cached jax-0.6.0-py3-none-any.whl (2.3 MB)\n",
      "Using cached jaxlib-0.6.0-cp312-cp312-win_amd64.whl (56.4 MB)\n",
      "Using cached opencv_contrib_python-4.11.0.86-cp37-abi3-win_amd64.whl (46.2 MB)\n",
      "Using cached sentencepiece-0.2.0-cp312-cp312-win_amd64.whl (991 kB)\n",
      "Using cached ml_dtypes-0.5.1-cp312-cp312-win_amd64.whl (210 kB)\n",
      "Using cached opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Installing collected packages: sentencepiece, flatbuffers, opt_einsum, opencv-contrib-python, ml_dtypes, absl-py, sounddevice, jaxlib, jax, mediapipe\n",
      "Successfully installed absl-py-2.2.2 flatbuffers-25.2.10 jax-0.6.0 jaxlib-0.6.0 mediapipe-0.10.21 ml_dtypes-0.5.1 opencv-contrib-python-4.11.0.86 opt_einsum-3.4.0 sentencepiece-0.2.0 sounddevice-0.5.2\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python mediapipe numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c72018e-34ff-40aa-989a-30717164023f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "class GestureController:\n",
    "    def __init__(self):\n",
    "        # Inicializar componentes de MediaPipe para detección de manos\n",
    "        self.mp_hands = mp.solutions.hands\n",
    "        self.hands = self.mp_hands.Hands(\n",
    "            static_image_mode=False,\n",
    "            max_num_hands=2,\n",
    "            min_detection_confidence=0.5,\n",
    "            min_tracking_confidence=0.5\n",
    "        )\n",
    "        self.mp_drawing = mp.solutions.drawing_utils\n",
    "        self.mp_drawing_styles = mp.solutions.drawing_styles\n",
    "        \n",
    "        # Variables para el control de interacción\n",
    "        self.bg_color = (0, 0, 0)  # Color de fondo inicial (negro)\n",
    "        self.object_position = [320, 240]  # Posición inicial del objeto [x, y]\n",
    "        self.scene = 0  # Escena actual (0, 1, 2)\n",
    "        self.scene_names = [\"Mover Objeto\", \"Cambiar Color\", \"Dibujar\"]\n",
    "        self.prev_hand_gesture = None\n",
    "        self.gesture_cooldown = 0  # Cooldown para evitar cambios rápidos\n",
    "        \n",
    "        # Variables para dibujo\n",
    "        self.drawing_points = []\n",
    "        self.is_drawing = False\n",
    "        self.draw_color = (0, 255, 0)  # Color verde para dibujar\n",
    "    \n",
    "    def process_frame(self, frame):\n",
    "        # Convertir la imagen a RGB (MediaPipe requiere RGB)\n",
    "        image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        h, w, _ = frame.shape\n",
    "        \n",
    "        # Procesar la imagen para detectar manos\n",
    "        results = self.hands.process(image_rgb)\n",
    "        \n",
    "        # Crear un marco transparente para dibujar sobre la imagen original\n",
    "        overlay = frame.copy()\n",
    "        \n",
    "        # Dibujar el fondo según la escena actual\n",
    "        if self.scene == 1:  # En la escena de cambio de color\n",
    "            cv2.rectangle(overlay, (0, 0), (w, h), self.bg_color, -1)\n",
    "        \n",
    "        # Verificar si se detectaron manos\n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                # Dibujar los puntos de referencia de la mano\n",
    "                self.mp_drawing.draw_landmarks(\n",
    "                    overlay, \n",
    "                    hand_landmarks, \n",
    "                    self.mp_hands.HAND_CONNECTIONS,\n",
    "                    self.mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "                    self.mp_drawing_styles.get_default_hand_connections_style()\n",
    "                )\n",
    "                \n",
    "                # Procesar gestos según la escena\n",
    "                if self.scene == 0:  # Escena: Mover Objeto\n",
    "                    self.handle_move_object(hand_landmarks, w, h)\n",
    "                elif self.scene == 1:  # Escena: Cambiar Color\n",
    "                    self.handle_change_color(hand_landmarks)\n",
    "                elif self.scene == 2:  # Escena: Dibujar\n",
    "                    self.handle_drawing(hand_landmarks, overlay, w, h)\n",
    "                \n",
    "                # Detectar gesto para cambiar de escena (palma abierta)\n",
    "                if time.time() > self.gesture_cooldown:\n",
    "                    current_gesture = self.detect_open_palm(hand_landmarks)\n",
    "                    \n",
    "                    # Si detectamos palma abierta y antes no estaba, cambiamos escena\n",
    "                    if current_gesture == \"open_palm\" and self.prev_hand_gesture != \"open_palm\":\n",
    "                        self.scene = (self.scene + 1) % len(self.scene_names)\n",
    "                        self.gesture_cooldown = time.time() + 1.5  # 1.5 segundos de cooldown\n",
    "                        self.drawing_points = []  # Limpiar puntos al cambiar escena\n",
    "                    \n",
    "                    self.prev_hand_gesture = current_gesture\n",
    "        \n",
    "        # Mezclar la imagen original con la capa de overlay\n",
    "        frame = cv2.addWeighted(overlay, 0.7, frame, 0.3, 0)\n",
    "        \n",
    "        # Dibujar elementos específicos de la escena actual\n",
    "        if self.scene == 0:  # Escena: Mover Objeto\n",
    "            # Dibujar el objeto controlado\n",
    "            cv2.circle(frame, (self.object_position[0], self.object_position[1]), 30, (0, 0, 255), -1)\n",
    "        elif self.scene == 2:  # Escena: Dibujar\n",
    "            # Dibujar los trazos del usuario\n",
    "            if len(self.drawing_points) > 1:\n",
    "                for i in range(1, len(self.drawing_points)):\n",
    "                    if self.drawing_points[i-1] is not None and self.drawing_points[i] is not None:\n",
    "                        cv2.line(frame, self.drawing_points[i-1], self.drawing_points[i], self.draw_color, 5)\n",
    "        \n",
    "        # Mostrar la escena actual en la pantalla\n",
    "        cv2.putText(frame, f\"Escena: {self.scene_names[self.scene]}\", (10, 30), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "        \n",
    "        if self.scene == 0:\n",
    "            cv2.putText(frame, \"Mueve el indice para controlar el circulo\", (10, 70), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "        elif self.scene == 1:\n",
    "            cv2.putText(frame, \"Abre/cierra la mano para cambiar color\", (10, 70), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "        elif self.scene == 2:\n",
    "            cv2.putText(frame, \"Indice+pulgar juntos para dibujar\", (10, 70), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "        \n",
    "        cv2.putText(frame, \"Muestra la palma abierta para cambiar de escena\", (10, h-30), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "            \n",
    "        return frame\n",
    "    \n",
    "    def handle_move_object(self, hand_landmarks, width, height):\n",
    "        # Usar la punta del dedo índice para mover el objeto\n",
    "        index_tip = hand_landmarks.landmark[self.mp_hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "        x, y = int(index_tip.x * width), int(index_tip.y * height)\n",
    "        \n",
    "        # Actualizar la posición del objeto\n",
    "        self.object_position = [x, y]\n",
    "    \n",
    "    def handle_change_color(self, hand_landmarks):\n",
    "        # Contar dedos extendidos para cambiar color\n",
    "        fingers_extended = self.count_fingers_extended(hand_landmarks)\n",
    "        \n",
    "        # Cambiar color según el número de dedos extendidos\n",
    "        if fingers_extended == 0:\n",
    "            self.bg_color = (0, 0, 0)  # Negro\n",
    "        elif fingers_extended == 1:\n",
    "            self.bg_color = (0, 0, 255)  # Rojo (BGR)\n",
    "        elif fingers_extended == 2:\n",
    "            self.bg_color = (0, 255, 0)  # Verde\n",
    "        elif fingers_extended == 3:\n",
    "            self.bg_color = (255, 0, 0)  # Azul\n",
    "        elif fingers_extended == 4:\n",
    "            self.bg_color = (0, 255, 255)  # Amarillo\n",
    "        elif fingers_extended == 5:\n",
    "            self.bg_color = (255, 0, 255)  # Magenta\n",
    "    \n",
    "    def handle_drawing(self, hand_landmarks, frame, width, height):\n",
    "        # Obtener coordenadas de las puntas de los dedos índice y pulgar\n",
    "        index_tip = hand_landmarks.landmark[self.mp_hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "        thumb_tip = hand_landmarks.landmark[self.mp_hands.HandLandmark.THUMB_TIP]\n",
    "        \n",
    "        # Convertir coordenadas normalizadas a píxeles\n",
    "        index_x, index_y = int(index_tip.x * width), int(index_tip.y * height)\n",
    "        thumb_x, thumb_y = int(thumb_tip.x * width), int(thumb_tip.y * height)\n",
    "        \n",
    "        # Calcular la distancia entre el pulgar y el índice\n",
    "        distance = ((index_x - thumb_x) ** 2 + (index_y - thumb_y) ** 2) ** 0.5\n",
    "        \n",
    "        # Si los dedos están cerca, estamos en modo dibujo\n",
    "        if distance < 40:  # Umbral de distancia para considerar \"pinza\"\n",
    "            if not self.is_drawing:\n",
    "                self.is_drawing = True\n",
    "                self.drawing_points.append(None)  # Marca un nuevo trazo\n",
    "            else:\n",
    "                self.drawing_points.append((index_x, index_y))\n",
    "        else:\n",
    "            self.is_drawing = False\n",
    "    \n",
    "    def count_fingers_extended(self, hand_landmarks):\n",
    "        # Puntos de referencia de las puntas de los dedos\n",
    "        finger_tips = [\n",
    "            self.mp_hands.HandLandmark.THUMB_TIP,\n",
    "            self.mp_hands.HandLandmark.INDEX_FINGER_TIP,\n",
    "            self.mp_hands.HandLandmark.MIDDLE_FINGER_TIP,\n",
    "            self.mp_hands.HandLandmark.RING_FINGER_TIP,\n",
    "            self.mp_hands.HandLandmark.PINKY_TIP\n",
    "        ]\n",
    "        # Puntos de referencia de las articulaciones intermedias (para verificar si el dedo está extendido)\n",
    "        finger_pips = [\n",
    "            self.mp_hands.HandLandmark.THUMB_IP,  # Para el pulgar usamos IP en lugar de PIP\n",
    "            self.mp_hands.HandLandmark.INDEX_FINGER_PIP,\n",
    "            self.mp_hands.HandLandmark.MIDDLE_FINGER_PIP,\n",
    "            self.mp_hands.HandLandmark.RING_FINGER_PIP,\n",
    "            self.mp_hands.HandLandmark.PINKY_PIP\n",
    "        ]\n",
    "        # Punto de referencia de la muñeca\n",
    "        wrist = hand_landmarks.landmark[self.mp_hands.HandLandmark.WRIST]\n",
    "        \n",
    "        count = 0\n",
    "        # Para el pulgar, el criterio es diferente (miramos si está lejos de la palma)\n",
    "        thumb_tip = hand_landmarks.landmark[finger_tips[0]]\n",
    "        thumb_base = hand_landmarks.landmark[self.mp_hands.HandLandmark.THUMB_CMC]\n",
    "        if thumb_tip.x < thumb_base.x:  # Simplificado para mano derecha\n",
    "            count += 1\n",
    "        \n",
    "        # Para los demás dedos\n",
    "        for i in range(1, 5):\n",
    "            tip = hand_landmarks.landmark[finger_tips[i]]\n",
    "            pip = hand_landmarks.landmark[finger_pips[i]]\n",
    "            \n",
    "            # Si la punta del dedo está más arriba que la articulación, el dedo está extendido\n",
    "            if tip.y < pip.y:\n",
    "                count += 1\n",
    "                \n",
    "        return count\n",
    "    \n",
    "    def detect_open_palm(self, hand_landmarks):\n",
    "        # Contar dedos extendidos\n",
    "        fingers = self.count_fingers_extended(hand_landmarks)\n",
    "        \n",
    "        # Si todos los dedos están extendidos, es palma abierta\n",
    "        if fingers >= 4:\n",
    "            return \"open_palm\"\n",
    "        return \"other\"\n",
    "\n",
    "def main():\n",
    "    # Inicializar la cámara\n",
    "    cap = cv2.VideoCapture(1)\n",
    "    \n",
    "    # Inicializar el controlador de gestos\n",
    "    gesture_controller = GestureController()\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        # Leer un frame de la cámara\n",
    "        success, frame = cap.read()\n",
    "        if not success:\n",
    "            print(\"Ignoring empty camera frame.\")\n",
    "            continue\n",
    "        \n",
    "        # Voltear la imagen horizontalmente para una vista tipo \"espejo\"\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        \n",
    "        # Procesar el frame con nuestro controlador de gestos\n",
    "        output_frame = gesture_controller.process_frame(frame)\n",
    "        \n",
    "        # Mostrar la imagen resultante\n",
    "        cv2.imshow('MediaPipe Hands Gesture Control', output_frame)\n",
    "        \n",
    "        # Salir si se presiona ESC\n",
    "        if cv2.waitKey(5) & 0xFF == 27:\n",
    "            break\n",
    "    \n",
    "    # Liberar recursos\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32b03f16-d6fc-47f2-9eed-bb82ad3d345f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cámara conectada correctamente.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(1)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"No se pudo abrir la cámara.\")\n",
    "else:\n",
    "    print(\"Cámara conectada correctamente.\")\n",
    "\n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c328972-ea1a-4b4d-b3c8-df9798bae0c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
