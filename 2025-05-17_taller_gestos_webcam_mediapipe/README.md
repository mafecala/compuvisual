# ğŸ§ª Taller - Gestos con CÃ¡mara Web: Control Visual con MediaPipe

## ğŸ“… Fecha

2025-05-17

## ğŸŒ· Equipo de trabajo

**Mi grupo estÃ¡ conformado por:**

- JuliÃ¡n RamÃ­rez DÃ­az (julramirezdi@unal.edu.co)
- Xamir Ernesto Rojas Gamboa (xerojasga@unal.edu.co)
- JuliÃ¡n David RincÃ³n Orjuela (jurinconor@unal.edu.co)
- MarÃ­a Fernanda Cala RodrÃ­guez (mcalar@unal.edu.co)

**Este taller fue realizado por:**
- MarÃ­a Fernanda Cala RodrÃ­guez (mcalar@unal.edu.co)

## ğŸ¯ Objetivo del Taller

Este taller tiene como objetivo explorar las interfaces naturales de usuario mediante la detecciÃ³n de gestos con las manos utilizando la cÃ¡mara web. A travÃ©s de la biblioteca MediaPipe y OpenCV, desarrollamos un sistema capaz de reconocer gestos en tiempo real y traducirlos en acciones visuales, creando una experiencia interactiva sin necesidad de hardware especializado.

## ğŸ§  Conceptos Aprendidos

âœ… Procesamiento de video en tiempo real con OpenCV
âœ… ImplementaciÃ³n de la detecciÃ³n de manos con MediaPipe
âœ… Reconocimiento de gestos y posturas de la mano
âœ… MediciÃ³n de distancias entre puntos de referencia (landmarks)
âœ… Conteo de dedos extendidos
âœ… CreaciÃ³n de interfaces naturales de usuario (NUI)
âœ… AplicaciÃ³n de transformaciones visuales basadas en gestos
âœ… Desarrollo de una mÃ¡quina de estados para manejar diferentes escenas interactivas

## ğŸ”§ Herramientas y Entornos

- Python
- OpenCV (`cv2`)
- MediaPipe
- NumPy
- Google Colab/Jupyter Notebook

## ğŸ“ Estructura del Proyecto

```
2025-05-17_taller_gestos_webcam_mediapipe/
â”œâ”€â”€ python/
â”‚   â””â”€â”€ taller13.ipynb
â””â”€â”€ README.md
```

## ğŸ§ª ImplementaciÃ³n

### ğŸ”¹ Funcionamiento de MediaPipe Hands

MediaPipe Hands es una soluciÃ³n de machine learning que permite la detecciÃ³n y el seguimiento de manos en tiempo real. El sistema funciona mediante los siguientes pasos:

1. **DetecciÃ³n inicial**: Localiza la mano en la imagen completa
2. **Seguimiento**: Predice la ubicaciÃ³n de 21 puntos de referencia (landmarks) de la mano
3. **RepresentaciÃ³n**: Cada punto tiene coordenadas (x, y, z) normalizadas, donde:
   - x e y son coordenadas de 0 a 1 relativas al ancho y alto de la imagen
   - z representa la profundidad relativa (siendo 0 la muÃ±eca)

![MediaPipe Hand Landmarks](https://mediapipe.dev/images/mobile/hand_landmarks.png)

### ğŸ”¹ Gestos implementados

El sistema implementa los siguientes gestos y acciones:

1. **Cambio de escena**: Mostrar la palma abierta (4-5 dedos extendidos)
2. **Mover objeto**: Seguimiento de la punta del dedo Ã­ndice
3. **Cambiar color de fondo**: Basado en el nÃºmero de dedos extendidos
4. **Dibujar**: Acercar las puntas del dedo Ã­ndice y pulgar ("pinza")

### ğŸ”¹ InteracciÃ³n en tiempo real

![Demo](demo3.gif)
![Demo](demo2.gif)
![Demo](demo1.gif)


## ğŸ”¹ CÃ³digo Relevante

Este fragmento muestra cÃ³mo detectamos los dedos extendidos para interpretar gestos:

```python
def count_fingers_extended(self, hand_landmarks):
    # Puntos de referencia de las puntas de los dedos
    finger_tips = [
        self.mp_hands.HandLandmark.THUMB_TIP,
        self.mp_hands.HandLandmark.INDEX_FINGER_TIP,
        self.mp_hands.HandLandmark.MIDDLE_FINGER_TIP,
        self.mp_hands.HandLandmark.RING_FINGER_TIP,
        self.mp_hands.HandLandmark.PINKY_TIP
    ]
    # Puntos de referencia de las articulaciones intermedias
    finger_pips = [
        self.mp_hands.HandLandmark.THUMB_IP,
        self.mp_hands.HandLandmark.INDEX_FINGER_PIP,
        self.mp_hands.HandLandmark.MIDDLE_FINGER_PIP,
        self.mp_hands.HandLandmark.RING_FINGER_PIP,
        self.mp_hands.HandLandmark.PINKY_PIP
    ]
    
    count = 0
    # Para el pulgar, criterio diferente
    thumb_tip = hand_landmarks.landmark[finger_tips[0]]
    thumb_base = hand_landmarks.landmark[self.mp_hands.HandLandmark.THUMB_CMC]
    if thumb_tip.x < thumb_base.x:  # Simplificado para mano derecha
        count += 1
    
    # Para los demÃ¡s dedos
    for i in range(1, 5):
        tip = hand_landmarks.landmark[finger_tips[i]]
        pip = hand_landmarks.landmark[finger_pips[i]]
        
        # Si la punta estÃ¡ mÃ¡s arriba que la articulaciÃ³n, el dedo estÃ¡ extendido
        if tip.y < pip.y:
            count += 1
            
    return count
```

## ğŸ§© Prompts Usados

### Prompt 1: GeneraciÃ³n del cÃ³digo base con MediaPipe

```
Crea un script en Python para detectar gestos con las manos utilizando MediaPipe y OpenCV. 
El programa debe:
1. Capturar video desde la webcam
2. Detectar las manos utilizando MediaPipe Hands
3. Implementar tres escenas distintas controladas por gestos:
   - Una escena donde se pueda mover un objeto siguiendo la punta del dedo Ã­ndice
   - Una escena donde el nÃºmero de dedos extendidos cambie el color de fondo
   - Una escena donde acercar el pulgar e Ã­ndice permita dibujar en pantalla
4. Permitir cambiar entre escenas mostrando la palma abierta
5. Incluir instrucciones en pantalla
6. Utilizar una estructura orientada a objetos bien organizada con comentarios claros
```

### Prompt 2: GeneraciÃ³n del README detallado

```
Crea un README.md completo para un taller titulado "Gestos con CÃ¡mara Web: Control Visual con MediaPipe". 
El README debe incluir:
1. TÃ­tulo, fecha y equipo de trabajo
2. Objetivo del taller claramente definido
3. Lista de conceptos aprendidos con emojis de verificaciÃ³n
4. Herramientas y entornos utilizados
5. Estructura del proyecto
6. ExplicaciÃ³n del funcionamiento de MediaPipe Hands
7. DescripciÃ³n de los gestos implementados
8. Secciones para GIFs de demostraciÃ³n
9. Un fragmento relevante de cÃ³digo comentado
10. La lista de prompts utilizados para generar el cÃ³digo
11. Una reflexiÃ³n final sobre la experiencia y posibles mejoras
Todo debe mantener un formato atractivo con emojis apropiados para cada secciÃ³n.
```

### Prompt 3: Mejoras especÃ­ficas para el reconocimiento de gestos

```
Mejora la funciÃ³n de detecciÃ³n de gestos con manos para que pueda:
1. Distinguir mÃ¡s claramente entre una palma abierta y otras posturas
2. Implementar un sistema de cooldown para evitar cambios rÃ¡pidos no intencionales
3. Mejorar la precisiÃ³n del conteo de dedos extendidos
4. Manejar correctamente la detecciÃ³n del pulgar (que funciona diferente a los otros dedos)
```

## ğŸ’¬ ReflexiÃ³n Final

Este taller me permitiÃ³ explorar la fascinante intersecciÃ³n entre la visiÃ³n por computadora y las interfaces naturales de usuario. La implementaciÃ³n del sistema de detecciÃ³n de gestos con MediaPipe revela el potencial de crear interfaces mÃ¡s intuitivas y accesibles sin necesidad de hardware especializado.

Durante el desarrollo, enfrentÃ© varios desafÃ­os interesantes:

1. **PrecisiÃ³n del seguimiento**: La iluminaciÃ³n y el fondo afectan significativamente la calidad de la detecciÃ³n. Mejorar las condiciones de luz y usar un fondo uniforme aumenta la precisiÃ³n considerablemente.

2. **InterpretaciÃ³n de gestos**: Distinguir con precisiÃ³n entre gestos similares requiere ajustar cuidadosamente los umbrales y crear lÃ³gica adicional para evitar falsos positivos.

3. **Latencia**: El procesamiento en tiempo real impone limitaciones de rendimiento, especialmente en hardware menos potente. La optimizaciÃ³n del cÃ³digo es crucial para mantener una experiencia fluida.

Para futuras mejoras, serÃ­a interesante:

- Implementar un sistema de reconocimiento de gestos basado en aprendizaje automÃ¡tico para identificar posturas mÃ¡s complejas
- AÃ±adir soporte para gestos con dos manos simultÃ¡neamente
- Explorar aplicaciones prÃ¡cticas como control de presentaciones o navegaciÃ³n de interfaces
- Reducir la dependencia de la iluminaciÃ³n mediante tÃ©cnicas de preprocesamiento de imagen mÃ¡s avanzadas

Este proyecto demuestra claramente cÃ³mo las tecnologÃ­as de visiÃ³n por computadora estÃ¡n transformando la forma en que interactuamos con los sistemas digitales, acercÃ¡ndonos cada vez mÃ¡s a interfaces que se adaptan naturalmente a nuestros movimientos y gestos intuitivos.