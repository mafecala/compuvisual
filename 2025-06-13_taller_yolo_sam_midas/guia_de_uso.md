# **üöÄ Gu√≠a Completa: C√≥mo Usar el Pipeline YOLO \+ SAM \+ MiDaS**

## **üìã Requisitos Previos**

* Cuenta de Google (para usar Google Colab)  
* Conexi√≥n a internet estable  
* Im√°genes para procesar (opcional, se incluye demo)

---

## **üîß PASO 1: Configuraci√≥n Inicial en Google Colab**

### **1.1 Abrir Google Colab**

1. Ve a [https://colab.research.google.com](https://colab.research.google.com/)  
2. Inicia sesi√≥n con tu cuenta de Google  
3. Crea un nuevo notebook: **Archivo \> Nuevo notebook**

### **1.2 Activar GPU (Recomendado)**

1. Ve a **Entorno de ejecuci√≥n \> Cambiar tipo de entorno de ejecuci√≥n**  
2. Selecciona **GPU** en "Acelerador de hardware"  
3. Haz clic en **Guardar**

### **1.3 Copiar el C√≥digo**

1. Copia todo el c√≥digo del pipeline en la primera celda del notebook  
2. Ejecuta la celda (Ctrl+Enter o bot√≥n ‚ñ∂Ô∏è)

---

## **üì¶ PASO 2: Instalaci√≥n de Dependencias**

### **2.1 Crear y Ejecutar Celda de Instalaci√≥n**

Crea una nueva celda y pega este c√≥digo:

\# Instalaci√≥n de todas las dependencias necesarias  
\!pip install ultralytics  
\!pip install segment-anything  
\!pip install opencv-python  
\!pip install timm  
\!pip install matplotlib  
\!pip install torch torchvision  
\!pip install numpy  
\!pip install Pillow  
\!pip install pandas

\# Descargar modelo SAM (archivo grande \~2.5GB)  
\!wget https://dl.fbaipublicfiles.com/segment\_anything/sam\_vit\_h\_4b8939.pth

\# Clonar repositorio SAM  
\!git clone https://github.com/facebookresearch/segment-anything.git

print("‚úÖ Instalaci√≥n completada\!")

**‚ö†Ô∏è IMPORTANTE**: Esta instalaci√≥n puede tomar 5-10 minutos. Espera a que termine antes de continuar.

---

## **üéØ PASO 3: Inicializaci√≥n del Pipeline**

### **3.1 Crear Celda de Inicializaci√≥n**

\# Inicializar el pipeline  
print("üîÑ Inicializando modelos...")  
pipeline \= VisionPipeline()  
print("‚úÖ Pipeline listo para usar\!")

**üìù Nota**: La primera vez puede tomar 2-3 minutos descargando modelos.

---

## **üñºÔ∏è PASO 4: Opciones para Procesar Im√°genes**

### **OPCI√ìN A: Demo con Imagen de Ejemplo (M√°s F√°cil)**

\# Ejecutar demo autom√°tico  
resultados \= demo\_con\_imagen\_ejemplo()

**¬øQu√© hace esto?**

* Descarga autom√°ticamente una imagen de ejemplo  
* Procesa la imagen completa  
* Muestra todas las visualizaciones  
* Guarda resultados en carpetas

### **OPCI√ìN B: Subir Tu Propia Imagen**

#### **B.1 Subir Imagen a Colab**

1. En el panel izquierdo, haz clic en el √≠cono de **üìÅ Archivos**  
2. Arrastra tu imagen desde tu computadora  
3. O haz clic en **üì§ Subir** y selecciona la imagen

#### **B.2 Procesar Tu Imagen**

\# Cambiar "mi\_imagen.jpg" por el nombre de tu archivo  
imagen\_path \= "/content/mi\_imagen.jpg"  
resultados \= pipeline.procesar\_imagen\_completa(imagen\_path)

### **OPCI√ìN C: Usar URL de Imagen**

import urllib.request

\# Descargar imagen desde URL  
url \= "https://ejemplo.com/mi\_imagen.jpg"  
urllib.request.urlretrieve(url, "imagen\_descargada.jpg")

\# Procesar  
resultados \= pipeline.procesar\_imagen\_completa("imagen\_descargada.jpg")

---

## **üîç PASO 5: Explorar Funcionalidades Individuales**

### **5.1 Solo Detecci√≥n YOLO**

\# Probar solo detecci√≥n de objetos  
detecciones \= pipeline.detectar\_objetos\_yolo("mi\_imagen.jpg", confidence=0.3)  
print(f"Objetos detectados: {detecciones\['nombres\_clases'\]}")  
print(f"Confianzas: {detecciones\['confianzas'\]}")

### **5.2 Solo Segmentaci√≥n SAM**

\# Primero detectar objetos  
detecciones \= pipeline.detectar\_objetos\_yolo("mi\_imagen.jpg")

\# Luego segmentar  
masks \= pipeline.segmentar\_con\_sam(detecciones\['imagen'\], detecciones\['boxes'\])  
print(f"M√°scaras generadas: {len(masks)}")

### **5.3 Solo Estimaci√≥n de Profundidad**

import cv2

\# Cargar imagen  
imagen \= cv2.imread("mi\_imagen.jpg")  
imagen\_rgb \= cv2.cvtColor(imagen, cv2.COLOR\_BGR2RGB)

\# Estimar profundidad  
depth\_map \= pipeline.estimar\_profundidad\_midas(imagen\_rgb)

\# Visualizar  
import matplotlib.pyplot as plt  
plt.figure(figsize=(10, 5))  
plt.subplot(1, 2, 1\)  
plt.imshow(imagen\_rgb)  
plt.title('Original')  
plt.axis('off')

plt.subplot(1, 2, 2\)  
plt.imshow(depth\_map, cmap='plasma')  
plt.title('Mapa de Profundidad')  
plt.axis('off')  
plt.show()

---

## **üé® PASO 6: Efectos Creativos**

### **6.1 Efecto Bokeh (Desenfoque de Fondo)**

\# Procesar imagen completa primero  
resultados \= pipeline.procesar\_imagen\_completa("mi\_imagen.jpg")

\# Aplicar efecto bokeh m√°s intenso  
imagen\_bokeh \= pipeline.aplicar\_efecto\_bokeh(  
    resultados\['detecciones'\]\['imagen'\],   
    resultados\['masks'\],   
    resultados\['depth\_map'\],  
    blur\_strength=25  \# M√°s desenfoque  
)

\# Mostrar resultado  
plt.figure(figsize=(12, 4))  
plt.subplot(1, 2, 1\)  
plt.imshow(resultados\['detecciones'\]\['imagen'\])  
plt.title('Original')  
plt.axis('off')

plt.subplot(1, 2, 2\)  
plt.imshow(imagen\_bokeh)  
plt.title('Efecto Bokeh')  
plt.axis('off')  
plt.show()

### **6.2 An√°lisis de Objetos por Distancia**

\# Obtener an√°lisis detallado  
df \= resultados\['analisis'\]

\# Mostrar objetos ordenados por cercan√≠a  
print("üèÜ OBJETOS M√ÅS CERCANOS:")  
print(df\[\['clase', 'distancia\_relativa', 'profundidad\_media'\]\].head())

\# Filtrar solo objetos cercanos  
objetos\_cercanos \= df\[df\['distancia\_relativa'\] \> 0.7\]  
print(f"\\nüìç Objetos en primer plano: {len(objetos\_cercanos)}")

---

## **üìÅ PASO 7: Trabajar con M√∫ltiples Im√°genes**

### **7.1 Crear Carpeta de Im√°genes**

import os  
os.makedirs('mis\_imagenes', exist\_ok=True)  
print("üìÅ Carpeta 'mis\_imagenes' creada")  
print("üëÜ Sube tus im√°genes a esta carpeta usando el panel de archivos")

### **7.2 Procesar Todas las Im√°genes**

\# Procesar todas las im√°genes de la carpeta  
procesar\_multiples\_imagenes('mis\_imagenes')

---

## **üìä PASO 8: Ver y Descargar Resultados**

### **8.1 Explorar Archivos Generados**

\# Ver estructura de archivos creados  
\!ls \-la outputs/  
\!ls \-la outputs/depth\_maps/  
\!ls \-la outputs/recortes/

### **8.2 Descargar Resultados**

1. Ve al panel de **üìÅ Archivos** en Colab  
2. Navega a la carpeta `outputs`  
3. Haz clic derecho en cualquier archivo  
4. Selecciona **Descargar**

### **8.3 Ver CSV con Estad√≠sticas**

import pandas as pd

\# Leer archivo CSV generado  
df \= pd.read\_csv('outputs/imagen\_analisis.csv')  
print("üìà ESTAD√çSTICAS COMPLETAS:")  
print(df.to\_string())

\# Crear gr√°fico de distancias  
import matplotlib.pyplot as plt  
plt.figure(figsize=(10, 6))  
plt.bar(df\['clase'\], df\['distancia\_relativa'\])  
plt.title('Distancia Relativa por Objeto')  
plt.xticks(rotation=45)  
plt.tight\_layout()  
plt.show()

---

## **üîß PASO 9: Personalizaci√≥n Avanzada**

### **9.1 Ajustar Par√°metros de Detecci√≥n**

\# Detectar m√°s objetos (menor confianza)  
detecciones \= pipeline.detectar\_objetos\_yolo("mi\_imagen.jpg", confidence=0.2)

\# Detectar menos objetos (mayor confianza)  
detecciones \= pipeline.detectar\_objetos\_yolo("mi\_imagen.jpg", confidence=0.8)

### **9.2 Crear Visualizaciones Personalizadas**

def mi\_visualizacion\_personalizada(imagen, masks, depth\_map, nombres):  
    """Crear tu propia visualizaci√≥n"""  
    plt.figure(figsize=(15, 5))  
      
    \# Panel 1: Imagen original  
    plt.subplot(1, 3, 1\)  
    plt.imshow(imagen)  
    plt.title('Mi Imagen')  
    plt.axis('off')  
      
    \# Panel 2: Solo m√°scaras  
    plt.subplot(1, 3, 2\)  
    combined\_mask \= np.zeros(imagen.shape\[:2\])  
    for i, mask in enumerate(masks):  
        combined\_mask\[mask\] \= i \+ 1  
    plt.imshow(combined\_mask, cmap='tab10')  
    plt.title('Segmentaci√≥n')  
    plt.axis('off')  
      
    \# Panel 3: Profundidad invertida (m√°s claro \= m√°s cerca)  
    plt.subplot(1, 3, 3\)  
    plt.imshow(1 \- depth\_map, cmap='hot')  
    plt.title('Cercan√≠a (Claro \= Cerca)')  
    plt.axis('off')  
      
    plt.tight\_layout()  
    plt.show()

\# Usar tu visualizaci√≥n  
resultados \= pipeline.procesar\_imagen\_completa("mi\_imagen.jpg")  
mi\_visualizacion\_personalizada(  
    resultados\['detecciones'\]\['imagen'\],  
    resultados\['masks'\],  
    resultados\['depth\_map'\],  
    resultados\['detecciones'\]\['nombres\_clases'\]  
)

---

## **üö® PASO 10: Soluci√≥n de Problemas Comunes**

### **Error: "No se detectaron objetos"**

**Soluci√≥n:**

\# Reducir umbral de confianza  
detecciones \= pipeline.detectar\_objetos\_yolo("mi\_imagen.jpg", confidence=0.1)

### **Error: "Out of memory"**

**Soluciones:**

1. Redimensionar imagen antes de procesar:

from PIL import Image  
img \= Image.open("mi\_imagen.jpg")  
img \= img.resize((800, 600))  \# Imagen m√°s peque√±a  
img.save("imagen\_pequena.jpg")

2. Usar modelo YOLO m√°s peque√±o:

pipeline.yolo\_model \= YOLO('yolov8n.pt')  \# Nano (m√°s r√°pido)

### **Error: "Archivo no encontrado"**

**Verificar ruta:**

import os  
print("Archivos disponibles:")  
print(os.listdir('/content/'))

---

## **üéØ PASO 11: Casos de Uso Espec√≠ficos**

### **11.1 An√°lisis de Seguridad**

\# Detectar personas y veh√≠culos  
def analizar\_seguridad(imagen\_path):  
    detecciones \= pipeline.detectar\_objetos\_yolo(imagen\_path, confidence=0.4)  
      
    personas \= \[i for i, clase in enumerate(detecciones\['nombres\_clases'\]) if 'person' in clase\]  
    vehiculos \= \[i for i, clase in enumerate(detecciones\['nombres\_clases'\]) if any(v in clase for v in \['car', 'truck', 'bus'\])\]  
      
    print(f"üë• Personas detectadas: {len(personas)}")  
    print(f"üöó Veh√≠culos detectados: {len(vehiculos)}")  
      
    return personas, vehiculos

\# Usar  
personas, vehiculos \= analizar\_seguridad("mi\_imagen.jpg")

### **11.2 An√°lisis de Retail**

\# Contar productos en estanter√≠a  
def contar\_productos(imagen\_path):  
    resultados \= pipeline.procesar\_imagen\_completa(imagen\_path)  
    df \= resultados\['analisis'\]  
      
    \# Productos por distancia  
    primer\_plano \= df\[df\['distancia\_relativa'\] \> 0.6\]  
    fondo \= df\[df\['distancia\_relativa'\] \<= 0.6\]  
      
    print(f"üõçÔ∏è Productos en primer plano: {len(primer\_plano)}")  
    print(f"üì¶ Productos en fondo: {len(fondo)}")  
      
    return primer\_plano, fondo

---

## **üìö PASO 12: Recursos Adicionales**

### **Documentaci√≥n de Modelos:**

* **YOLO**: [https://docs.ultralytics.com](https://docs.ultralytics.com/)  
* **SAM**: [https://github.com/facebookresearch/segment-anything](https://github.com/facebookresearch/segment-anything)  
* **MiDaS**: [https://github.com/intel-isl/MiDaS](https://github.com/intel-isl/MiDaS)

### **Tipos de Im√°genes Ideales:**

* ‚úÖ **Buenas**: Fotos claras, buena iluminaci√≥n, objetos bien definidos  
* ‚úÖ **Perfectas**: Escenas urbanas, interiores, retratos con fondo  
* ‚ö†Ô∏è **Dif√≠ciles**: Im√°genes muy oscuras, objetos muy peque√±os, escenas complejas

### **L√≠mites del Sistema:**

* **Memoria**: Im√°genes muy grandes (\>4K) pueden causar errores  
* **Precisi√≥n**: Objetos muy peque√±os pueden no detectarse  
* **Velocidad**: Procesamiento puede tomar 30-60 segundos por imagen

---

