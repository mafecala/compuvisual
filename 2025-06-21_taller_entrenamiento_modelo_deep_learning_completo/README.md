# ğŸ§ª Taller - Entrenamiento de un Modelo de Deep Learning de Inicio a Fin

## ğŸ“… Fecha

2025-06-20


##  ğŸŒ· Equipo de trabajo

  

  

**Mi grupo estÃ¡ conformado por:**

  

  

- JuliÃ¡n RamÃ­rez DÃ­az (julramirezdi@unal.edu.co)

  

- JuliÃ¡n David RincÃ³n Orjuela (jurinconor@unal.edu.co)

  

- MarÃ­a Fernanda Cala RodrÃ­guez (mcalar@unal.edu.co)

  

  

**Este taller fue realizado por:**

  

  

- MarÃ­a Fernanda Cala RodrÃ­guez (mcalar@unal.edu.co)

## ğŸ” Objetivo del Taller

Guiar paso a paso el proceso de entrenamiento de un modelo de aprendizaje profundo utilizando PyTorch. El objetivo es que el estudiante comprenda y ejecute cada etapa fundamental: carga y preprocesamiento de datos, definiciÃ³n del modelo, entrenamiento, validaciÃ³n cruzada, evaluaciÃ³n, fine-tuning y exportaciÃ³n del modelo final.

---

## ğŸ§  Conceptos Aprendidos

âœ… Uso de PyTorch para clasificaciÃ³n de imÃ¡genes  
âœ… Carga y preprocesamiento de datasets con torchvision  
âœ… SeparaciÃ³n de datos para entrenamiento y validaciÃ³n  
âœ… DefiniciÃ³n de redes neuronales con `nn.Sequential`  
âœ… FunciÃ³n de pÃ©rdida y optimizaciÃ³n con Adam  
âœ… EvaluaciÃ³n con mÃ©tricas y matriz de confusiÃ³n  
âœ… ValidaciÃ³n cruzada con K-Fold  
âœ… Fine-tuning con modelos preentrenados (ResNet18)  
âœ… Guardado y carga de modelos entrenados  

---

## ğŸ”§ Herramientas y Entornos

- Python 3.10+
- PyTorch (`torch`, `torchvision`)
- NumPy
- Matplotlib
- scikit-learn
- seaborn (visualizaciÃ³n)
- tqdm (opcional)

---

## ğŸ“ Estructura del Proyecto

2025-06-21_taller_entrenamiento_modelo_deep_learning_completo/
â”œâ”€â”€ data/
â”œâ”€â”€ python/
â”‚   â””â”€â”€ entrenamiento_modelo.py
â”œâ”€â”€ modelos/
â”‚   â””â”€â”€ modelo_mnist.pth
â”œâ”€â”€ resultados/
â”‚   â”œâ”€â”€ curva.png
â”‚   â”œâ”€â”€ matriz.png
â”‚   â”œâ”€â”€ metricas_entrenamiento.npz
â”œâ”€â”€ README.md

---

## ğŸ”¹ DescripciÃ³n de las Acciones del Modelo

El modelo fue entrenado para reconocer dÃ­gitos del 0 al 9 usando el dataset **MNIST**. Las etapas incluyeron:

- VisualizaciÃ³n de ejemplos
- SeparaciÃ³n 80/20 para entrenamiento y validaciÃ³n
- EvaluaciÃ³n con matriz de confusiÃ³n
- Fine-tuning con ResNet18 preentrenada

---

## ğŸï¸ Capturas

![Demo](resultados/curva.png)
![Demo](resultados/matriz.png)

---

## ğŸ’» Fragmentos de CÃ³digo Relevante

### âœ… Carga del dataset y visualizaciÃ³n

```
from torchvision import datasets, transforms

transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,))
])

train_data = datasets.MNIST(root='data', train=True, download=True, transform=transform)
test_data  = datasets.MNIST(root='data', train=False, download=True, transform=transform)
âœ… DefiniciÃ³n del modelo
python
Copiar
Editar
import torch.nn as nn

model = nn.Sequential(
    nn.Flatten(),
    nn.Linear(28*28, 128),
    nn.ReLU(),
    nn.Dropout(0.2),
    nn.Linear(128, 64),
    nn.ReLU(),
    nn.Linear(64, 10)
)
âœ… Entrenamiento
python
Copiar
Editar
for epoch in range(epochs):
    model.train()
    for images, labels in train_loader:
        ...
        optimizer.zero_grad()
        output = model(images)
        loss = criterion(output, labels)
        loss.backward()
        optimizer.step()
âœ… Fine-tuning con ResNet18
python
Copiar
Editar
from torchvision import models

model_ft = models.resnet18(pretrained=True)
for param in model_ft.parameters():
    param.requires_grad = False

num_ftrs = model_ft.fc.in_features
model_ft.fc = nn.Linear(num_ftrs, 10)
```

## ğŸ¤– Resultados y EvaluaciÃ³n

ğŸ“Œ PrecisiÃ³n de validaciÃ³n alcanzada: ~97%
ğŸ“Œ PrecisiÃ³n de test con modelo fine-tuneado: ~98%
ğŸ“Œ Mejores resultados con fine-tuning completo (descongelar todas las capas)
ğŸ“Œ Matriz de confusiÃ³n muestra mayor confusiÃ³n entre 4 y 9

## ğŸ’¬ Prompts usados para generaciÃ³n

### ğŸ§  Prompt 1: Flujo completo de entrenamiento

`Crea  un  script  en  PyTorch  para  entrenar  un  modelo  de  clasificaciÃ³n  con  MNIST  o  CIFAR-10. Incluye: carga  y  visualizaciÃ³n  del  dataset, creaciÃ³n  de  dataloaders, definiciÃ³n  de  modelo, entrenamiento, validaciÃ³n, evaluaciÃ³n  y  guardado  del  modelo  final.` 

----------

### ğŸ§© Prompt 2: Fine-Tuning con modelo preentrenado

`Agrega al proyecto un ejemplo de fine-tuning usando ResNet18 de torchvision. Congela las capas preentrenadas, reemplaza la capa final por una compatible con 10 clases y entrena solo esa. Luego, repite con todas las capas descongeladas.` 

----------

### ğŸ“„ Prompt 3: GeneraciÃ³n del README acadÃ©mico

`Genera un README.md completo para un taller titulado "Entrenamiento de un Modelo de Deep Learning de Inicio a Fin". Debe incluir: tÃ­tulo, fecha, equipo, objetivo del taller, pasos detallados del flujo de entrenamiento, herramientas usadas, fragmentos de cÃ³digo clave, visualizaciones, reflexiÃ³n final y los prompts utilizados.`

## ğŸ’¡ ReflexiÃ³n Final

Durante el desarrollo de este taller, la acciÃ³n mÃ¡s fÃ¡cil de implementar fue el entrenamiento base con MNIST por su simplicidad y tamaÃ±o reducido. El fine-tuning resultÃ³ ser el paso mÃ¡s enriquecedor, ya que demostrÃ³ cÃ³mo aprovechar modelos preentrenados para acelerar el aprendizaje y mejorar resultados. Las principales dificultades surgieron al ajustar las dimensiones del modelo ResNet para tareas especÃ­ficas.

Â¿Hubo falsos positivos o errores?
SÃ­, algunos errores de predicciÃ³n ocurrieron entre dÃ­gitos similares (como 4 y 9), lo cual es comÃºn en modelos entrenados sin data augmentation.

Este taller me permitiÃ³ consolidar el flujo completo de un proyecto de deep learning y sentar las bases para futuros modelos mÃ¡s complejos y personalizados.

